Title: Hostbot-AI: Finding Promising New Users in Wikipedia with Machine Learning
Date: 2019-11-20 02:58
Author: max
Slug: 4266
Status: draft

Overview
--------

Can machine learning identify and connect the best newcomers to Wikipedia with mentors and keep them editing for longer ? That's what I aimed to find out during my stint with the [Wikimedia Foundation Scoring Platform Team](https://www.mediawiki.org/wiki/Wikimedia_Scoring_Platform_team).

Matching newcomers with mentors is seen as a promising way to help reverse Wikipedia's trend in declining active editors. But because they are volunteer human resource we ought to very wisely use their time. A heuristic model has been the champion way that newcomers are invited to the English Wikipedia TeaHouse for 4 years, but there was the idea to improve upon it with AI. Based on the [ORES platform](https://www.mediawiki.org/wiki/ORES), I labelled the data for, and trained a new model to predict the potential of a new user after their third edit. Then in a 6-month long A/B test we saw if it could increase retention of newcomers against the heursitic model as a baseline. The results which came from inviting over 10,000 real-world users were unfortunately mixed. In the short and medium-term users identified by AI came back more often, but perplexingly the reverse was true in long-term analysis. The results demand further investigation, still a lot of key technology to complete those follow-ups were built along the way.

Motivation
----------

Wikipedia is facing a decline in active editors, which is why addressing the problem of retaining new editors has received so much attention over the past decade. One popular solution is

### Creating the machine learning model

Wikimedia's [*Objective Revision Evaluation Service*]{.reference-text} (ORES) is a predictive algorithm that can already predict the quality of *single edits* and *articles*, this project extended that capability to *sessions* of multiple related edits. As this was a supervised machine learning problem, I created and labelled a dataset of sessions, using the Wikilabels system, committing a new labelling class back to the project (see https://en.wikipedia.org/wiki/Wikipedia:Labels/Newcomer\_session\_quality).

#### [Feature lists]{#Feature_lists .mw-headline}

The basic features that I engineered to predict a session were:

-   basic statistics of the underlying goodfaith scores of the session's edits
-   slope and intercept of a line drawn through the goodfaith scores of the session's edits edit as a time-vector
-   temporal statistics of the inter-edit times of the session's edits
-   the self-reverts of the user
-   whether the user appears to be in an edit war
-   statistics about the namespaces used in the session's edits
-   see more in the [ipynb](https://github.com/notconfusing/newcomerquality/blob/master/ipython/Newcomer%20quality%20-%20feature%20eng%20and%20feature%20importance.ipynb){.external .text}.

#### [The model]{#The_model .mw-headline}

-   The metric used for scoring models chose was precision at k=300 which mirrors the domains problem of choosing the best 300 editors to invite each day.
-   I then ran Rayid Ghani's classic "magicloops" \<link\> method of finding hyperparamaters and models that maximized the metric under cross validation.
-   Both gradient boosting and logistic regression appear to achieve approximately 95% precision in the top 300 most confident predictions, and cross-validation appeared steady. The prior for the goodfaith class is approximately 74% (most newcomer sessions are goodfaith) so we are definietly learning something .

The model was now trained and ready to be integrated into our experiment in production.

More details on the training and open source library. P.S. the session-oriented scoring is coming soon back upstream into the official ORES service.

 

1.  what is a session, why is a session needed. what is ores
2.  the labelling campaign https://en.wikipedia.org/wiki/Wikipedia:Labels/Newcomer\_session\_quality
3.  how to create the score for multiple sessions
4.  \- goodfath of sessions. the minimum (this makes it strict). Is it influencing results?
5.  model selection (i think i wrote about this in an ipy before)
6.  production threshold perday (search for  the threshold where i would get 150 users per day)
7.  Fuller details at this Mediawiki page.
8.  soon to be incorporated  into ORES proper
9.  github links

Experimental Design
-------------------

 

A/b test on odd and even.

Just tetsting which method is better, desipte the fact that each could have its control. Heuristic is already proven to increase above control.

Results
-------

full analysis: https://paws-public.wmflabs.org/paws-public/User:Maximilianklein/hostbot-ai/hostbot-ai%20analysis.ipynb

The number one concern that Wikipedia for Wikipedia are to "retain" newcomers, that is to have them continue editing after their intitial joining—this is also known as "survival". The official retention measures from the Wikimedia Foundation are defined by a "trial period" (the inital spurt) the "suvival period" (when they return) and how many edits in the survival period define a return. (See a detailed explanation)\[https://meta.wikimedia.org/wiki/Research:Surviving\_new\_editor\] . We looked at 10 retention measures for different paramter definitions of retention. Finally, for each measure, we conduct an independent t-test between the retention data (binary outcomes) of HostBot versus HostBot-AI. The table below outlines the results.

#### 2015 Paper Measures

These measures come from the 2015.

The trial weeks are the number of weeks after registration, the survival weeks are the window after the trial, and the edits are the number of required edits to make to be considered survived.

  trial: survival:edits   ai\_heur\_per\_diff   ai\_heur\_p\_value
  ----------------------- --------------------- --------------------
  1 : 1 : 1               -1.076                0.467
  1 : 3 : 1               0.912                 0.026
  3 : 1 : 1               1.750                 0.000
  3 : 1 : 5               0.620                 0.053
  4 : 4 : 1               2.935                 0.000
  4 : 4 : 5               2.425                 0.000
  8 : 16 : 1              -2.261                0.010
  8 : 16 : 5              -1.459                0.026

![]({static}/images/uploads/2019/11/measure1.png){.alignright .size-full .wp-image-4270 style="width:515px !important"}

Survival Measures

                        heur\_measure   ai\_measure   ai\_heur\_improvement   tstat    pval
  --------------------- --------------- ------------- ----------------------- -------- -------
  survival\_days\_14    1.776           1.712         -0.064                  0.976    0.329
  survival\_days\_28    4.070           4.527         0.457                   -3.014   0.003
  survival\_days\_56    8.363           10.107        1.744                   -5.595   0.000
  survival\_days\_168   22.456          20.780        -1.676                  2.121    0.034
  survival\_edits       20.850          15.146        -5.704                  8.730    0.000

 

![]({static}/images/uploads/2019/11/measure2-1.png){.alignright .size-full .wp-image-4272 style="width:470px !important"}
--------------------------------------------------------------------------------------------------------------------------------------

![]({static}/images/uploads/2019/11/measure3.png){.alignright .size-full .wp-image-4268 style="width:472px !important"}

Future Designs.
---------------
